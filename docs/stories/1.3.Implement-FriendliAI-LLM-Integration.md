# Story 1.3: Implement FriendliAI LLM Integration

- **Status:** Done

## Story

- **As an** AI Agent,
- **I want** to analyze the retrieved knowledge from Weaviate and identify the top 3 missing skills required for the career transition,
- **so that** I can provide personalized, actionable recommendations to the user.

## Acceptance Criteria

1. The backend can connect to FriendliAI API using proper authentication.
2. The backend can send a structured prompt to FriendliAI that includes:
   - User's current role
   - User's target role
   - Retrieved documents from Weaviate
3. FriendliAI analyzes the context and returns the top 3 skills to learn.
4. The response is parsed and structured for the next workflow step.
5. Error handling is implemented for API failures and invalid responses.

## Tasks / Subtasks

- [x] **Task 1 (AC: 1):** Set up FriendliAI client connection with proper authentication.
  - [x] Install `friendli` Python package or use HTTP client
  - [x] Configure API key from environment variables
  - [x] Add connection validation logic
- [x] **Task 2 (AC: 2, 3):** Implement the LLM analysis function that processes Weaviate results.
  - [x] Create function `analyze_skill_gap(current_role: str, target_role: str, knowledge_docs: list)`
  - [x] Design prompt template that includes role context and retrieved documents
  - [x] Configure model parameters (temperature, max_tokens, etc.)
  - [x] Send request to FriendliAI API
- [x] **Task 3 (AC: 4):** Parse and structure the FriendliAI response.
  - [x] Extract the top 3 skills from the LLM response
  - [x] Format as a structured list for downstream processing
  - [x] Validate response format
- [x] **Task 4 (AC: 5):** Add error handling for FriendliAI API failures.
  - [x] Handle authentication errors
  - [x] Handle rate limiting
  - [x] Handle timeout errors
  - [x] Handle malformed responses
  - [x] Log errors appropriately

## Dev Notes

### Tech Stack

- **Backend Language:** Python 3.11+ [Source: architecture.md#tech-stack]
- **Backend Framework:** FastAPI [Source: architecture.md#tech-stack]
- **LLM Provider:** FriendliAI [Source: architecture.md#tech-stack]
- **Model:** Llama 3 8B or similar (fast, small-to-medium-sized model) [Source: prd.md#technical-specifications]

### FriendliAI Configuration

- **Model Selection:** Use a fast, small-to-medium-sized model (e.g., Llama 3 8B) for quick inference [Source: prd.md#technical-specifications]
- **Capability Required:** The model must be capable of Tool-Calling/Function-Calling to utilize aci.dev in the next story [Source: prd.md#technical-specifications]
- **Environment Variables Required:**
  - `FRIENDLI_TOKEN`: Authentication token for FriendliAI API
  - `FRIENDLI_MODEL`: Model identifier (e.g., "meta-llama-3.1-8b-instruct")
  - `FRIENDLI_BASE_URL`: Base URL for serverless API (e.g., "https://api.friendli.ai/serverless/v1")

### Prompt Engineering

The prompt should include:

1. **System Context:** Role as a career advisor AI
2. **User Context:** Current role and target role
3. **Retrieved Knowledge:** Documents from Weaviate about the target role
4. **Task:** Identify exactly 3 skills the user needs to learn for the transition
5. **Output Format:** Structured list of skills

Example prompt structure:

```
You are a career advisor AI helping developers transition between roles.

Current Role: {current_role}
Target Role: {target_role}

Based on the following knowledge about the target role:
{weaviate_documents}

Identify the top 3 most important skills this person needs to learn to successfully transition from their current role to the target role.

Return your response as a JSON array of exactly 3 skill names.
```

### API Integration

- **Request Format:**
  - Model: String (model identifier)
  - Messages: Array of message objects (system, user)
  - Temperature: Float (0.7 recommended for balanced creativity)
  - Max Tokens: Integer (500-1000 for skill list generation)
- **Response Format:**
  - Parse JSON response
  - Extract skills array
  - Validate exactly 3 skills returned

### File Locations

- **Backend Code:** Create `api/friendli_client.py` for FriendliAI integration [Source: architecture.md#unified-project-structure]
- **Main Orchestrator:** Update `api/index.py` to call FriendliAI after Weaviate [Source: architecture.md#unified-project-structure]
- **Environment Config:** Add to `.env` file (not committed), update `.env.example` [Source: architecture.md#unified-project-structure]
- **Dependencies:** Add to `api/requirements.txt` [Source: architecture.md#unified-project-structure]

### Data Flow

This is Step 5-8 in the core workflow:

1. Backend receives user input (Current Role, Target Role)
2. Backend queries Weaviate with Target Role (Story 1.2 - COMPLETED)
3. Weaviate returns relevant skill documents (Story 1.2 - COMPLETED)
4. **→ Backend passes documents to FriendliAI for analysis (THIS STORY)**
5. **→ FriendliAI analyzes and returns top 3 skills (THIS STORY)**
6. Backend will use FriendliAI to call aci.dev tool for course recommendations (Next Story)
   [Source: architecture.md#core-workflows]

### Previous Story Insights

From Story 1.2 (Weaviate RAG Integration):

- Weaviate returns documents with `title`, `description`, and `category` fields
- The `query_job_knowledge()` function returns a list of dictionaries
- Top 3-5 documents are retrieved based on semantic similarity
  [Source: docs/stories/1.2.Implement-Weaviate-RAG-Integration.md]

### Integration Points

- **Input:** Receives `current_role`, `target_role`, and `knowledge_docs` from Weaviate
- **Output:** Returns list of 3 skill names as strings
- **Next Step:** These skills will be passed to aci.dev tool calling in Story 1.4

### Testing Requirements

- **Testing Strategy:** Manual testing for MVP, no automated tests required [Source: architecture.md#testing-strategy]
- **Manual Test Cases:**
  - Test successful connection to FriendliAI
  - Test skill gap analysis with valid roles (e.g., "Frontend Developer" → "Machine Learning Engineer")
  - Test with edge cases (same current and target role)
  - Test error handling for API failures
  - Verify exactly 3 skills are returned
  - Verify skills are relevant to the career transition

### Error Handling

- Implement try-catch blocks for all FriendliAI operations
- Return meaningful error messages to the orchestrator
- Log all errors for debugging purposes
- Consider fallback behavior if FriendliAI is unavailable (e.g., return generic skills)

### Performance Considerations

- Set appropriate timeout values (e.g., 30 seconds)
- Use streaming if available for faster perceived response time
- Cache responses if the same role combination is queried multiple times (optional for MVP)

## Change Log

| Date       | Version | Description                                  | Author               |
| :--------- | :------ | :------------------------------------------- | :------------------- |
| 2025-10-02 | 1.0     | Initial draft                                | Bob (Scrum Master)   |
| 2025-10-02 | 2.0     | Implementation completed - All tests passing | Full Stack Developer |
