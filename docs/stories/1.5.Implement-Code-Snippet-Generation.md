# Story 1.5: Implement Code Snippet Generation

- **Status:** Done

## Story

- **As a** career-changing developer,
- **I want** to see a practical, runnable code example for my top priority skill,
- **so that** I can immediately start practicing and understand what I'll be learning.

## Acceptance Criteria

1. The backend can generate a code snippet for the first skill from the top 3 recommended skills.
2. The code snippet is a short, functional example (5-10 lines) demonstrating the skill.
3. The code snippet is in an appropriate language for the skill (e.g., Python for ML, JavaScript for React).
4. The generated code includes comments explaining what it does.
5. The code snippet is integrated into the final career path response.
6. Error handling is implemented for code generation failures.

## Tasks / Subtasks

- [ ] **Task 1 (AC: 1, 2):** Implement code generation function using FriendliAI.
  - [ ] Create function `generate_code_snippet(skill: str)` in `api/friendli_client.py`
  - [ ] Design prompt template for code generation
  - [ ] Configure FriendliAI to generate concise, functional code examples
- [ ] **Task 2 (AC: 3, 4):** Ensure language-appropriate code generation.
  - [ ] Add logic to determine appropriate programming language based on skill
  - [ ] Include comments in generated code
  - [ ] Validate code syntax (basic validation)
- [ ] **Task 3 (AC: 5):** Integrate code snippet into career path response.
  - [ ] Update `CareerPath` response model to include code snippet
  - [ ] Add code snippet to the first skill in the response
  - [ ] Format code snippet for display (preserve formatting)
- [ ] **Task 4 (AC: 6):** Add error handling for code generation.
  - [ ] Handle FriendliAI API failures
  - [ ] Handle invalid or malformed code responses
  - [ ] Provide fallback behavior if code generation fails
  - [ ] Log errors appropriately

## Dev Notes

### Tech Stack

- **Backend Language:** Python 3.11+ [Source: architecture.md#tech-stack]
- **Backend Framework:** FastAPI [Source: architecture.md#tech-stack]
- **LLM Provider:** FriendliAI (Llama 3.1 8B Instruct) [Source: prd.md#technical-specifications]

### Code Generation Requirements

From PRD S5:

> "As the AI Agent, I can generate a code snippet demonstrating the first recommended skill (e.g., a "Hello World" of that technology). FriendliAI (LLM): Generate a short, 5-line Python script."

**Key Requirements:**

- Generate code for the **first skill only** (not all 3) - this is the highest priority skill
- Keep it short: 5-10 lines maximum for quick comprehension
- Must be functional and runnable - users should be able to copy-paste and execute
- Include explanatory comments - educational value is critical
- Language should match the skill (Python for ML/Data Science, JavaScript for frontend, etc.)
- Code should demonstrate a **core concept** of the skill, not just "Hello World"

**User Value:**

- Provides immediate, tangible learning material
- Reduces intimidation factor by showing a simple, achievable example
- Validates that the skill recommendation is actionable
- Serves as a starting point for hands-on practice

### Skill-to-Language Mapping

Default language mappings:

- **Python Skills:** Machine Learning, Data Science, TensorFlow, PyTorch, Pandas, NumPy, Django, Flask
- **JavaScript Skills:** React, Vue, Angular, Node.js, Express, Next.js
- **Other Languages:**
  - Java: Spring Boot, Android
  - Go: Microservices, Docker, Kubernetes
  - SQL: Database skills
  - Default: Python (if skill doesn't match any category)

### Code Generation Prompt Template

Example prompt structure:

```
Generate a short, functional code snippet (5-10 lines) demonstrating the skill: {skill_name}.

Requirements:
- Use {language} programming language
- Include comments explaining what the code does
- Make it a complete, runnable example
- Keep it simple and educational
- Focus on the core concept of {skill_name}

Return only the code snippet, no additional explanation.
```

### Example Code Snippets

**Machine Learning (Python):**

```python
# Simple linear regression example using scikit-learn
from sklearn.linear_model import LinearRegression
import numpy as np

# Sample data: hours studied vs exam score
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([2, 4, 5, 4, 5])

# Train model and predict
model = LinearRegression().fit(X, y)
print(f"Predicted score for 6 hours: {model.predict([[6]])[0]:.2f}")
```

**React (JavaScript):**

```javascript
// Simple React counter component
import React, { useState } from "react"

function Counter() {
  const [count, setCount] = useState(0)

  return (
    <div>
      <p>Count: {count}</p>
      <button onClick={() => setCount(count + 1)}>Increment</button>
    </div>
  )
}
```

### File Locations

- **Code Generation Function:** Add to `api/friendli_client.py` [Source: architecture.md#unified-project-structure]
- **Main Orchestrator:** Update `api/index.py` to call code generation [Source: architecture.md#unified-project-structure]
- **Response Model:** Update in `api/index.py` (or create `api/models.py` if needed)

### Data Flow

This is Step 12-13 in the core workflow:

1. Backend receives user input (Current Role, Target Role)
2. Backend queries Weaviate with Target Role (Story 1.2 - COMPLETED)
3. Weaviate returns relevant skill documents (Story 1.2 - COMPLETED)
4. Backend passes documents to FriendliAI for analysis (Story 1.3 - COMPLETED)
5. FriendliAI analyzes and returns top 3 skills (Story 1.3 - COMPLETED)
6. FriendliAI calls aci.dev tool for each skill (Story 1.4 - COMPLETED)
7. aci.dev executes `search_learning_content` and returns courses (Story 1.4 - COMPLETED)
8. Backend integrates course recommendations into response (Story 1.4 - COMPLETED)
9. **→ Backend calls FriendliAI to generate code snippet for first skill (THIS STORY)**
10. **→ Backend integrates code snippet into response (THIS STORY)**
11. Backend will send code to Daytona for validation (Next Story - 1.6)
12. Backend will log everything to Comet (Story 1.7)
    [Source: architecture.md#core-workflows]

### Previous Story Insights

From Story 1.4 (aci.dev Tool Calling):

- The response model includes a list of 3 skills with course recommendations
- Each skill has a name and a list of courses
- The first skill in the list should receive the code snippet
  [Source: docs/stories/1.4.Implement-aci.dev-Tool-Calling.md]

### Integration Points

- **Input:** Receives the first skill name from the top 3 recommended skills (highest priority)
- **Output:** Returns a formatted code snippet string to be added to the career path response
- **Next Step:** Daytona validation (Story 1.6) will execute and validate this generated code
- **User Experience:** Code snippet will be displayed in a code block with syntax highlighting in the frontend

### Response Model Update

Update the `CareerPath` response model to include code snippet with metadata:

```python
class CodeSnippet(BaseModel):
    code: str  # The actual code
    language: str  # Programming language (e.g., "python", "javascript")
    description: str  # Brief description of what the code does

class Skill(BaseModel):
    name: str
    courses: List[Course]
    code_snippet: Optional[CodeSnippet] = None  # Only populated for first skill

class CareerPath(BaseModel):
    current_role: str
    target_role: str
    skills: List[Skill]
    # ... other fields
```

**Rationale:** Including language and description metadata enables:

- Proper syntax highlighting in the frontend
- Better user understanding of the code's purpose
- Easier integration with code execution tools (Daytona)

### FriendliAI Configuration

- **Model:** Llama 3.1 8B Instruct (same as skill gap analysis)
- **Temperature:** 0.7 (allow some creativity but keep it focused)
- **Max Tokens:** 200-300 (enough for 5-10 lines of code + comments)
- **System Prompt:** Emphasize generating clean, educational code examples

### Testing Requirements

- **Testing Strategy:** Manual testing for MVP, no automated tests required [Source: architecture.md#testing-strategy]

#### Test Categories

**1. Functional Tests (Core Functionality)**

- [ ] **TC-F1:** Generate code for Python-based skills
  - Input: Skill = "Machine Learning"
  - Expected: Python code with ML example (e.g., scikit-learn)
  - Verify: Code is syntactically valid Python
- [ ] **TC-F2:** Generate code for JavaScript-based skills
  - Input: Skill = "React"
  - Expected: JavaScript/JSX code with React example
  - Verify: Code is syntactically valid JavaScript
- [ ] **TC-F3:** Generate code for unknown/generic skills
  - Input: Skill = "Problem Solving"
  - Expected: Default to Python with generic example
  - Verify: Fallback behavior works correctly
- [ ] **TC-F4:** Verify code length constraints
  - Expected: Code is between 5-10 lines (excluding blank lines)
  - Verify: Not too verbose, not too minimal
- [ ] **TC-F5:** Verify comment inclusion
  - Expected: Code includes at least 2-3 explanatory comments
  - Verify: Comments explain what and why

**2. Quality Tests (Code Quality & Educational Value)**

- [ ] **TC-Q1:** Code demonstrates core concept
  - Verify: Code shows a meaningful use case, not just "Hello World"
  - Example: For "Machine Learning", show actual model training
- [ ] **TC-Q2:** Code is runnable
  - Test: Copy-paste code into appropriate environment
  - Expected: Code executes without errors (assuming dependencies installed)
  - Verify: No syntax errors, no undefined variables
- [ ] **TC-Q3:** Code is beginner-friendly
  - Verify: Uses simple, clear variable names
  - Verify: Avoids complex patterns or advanced features
  - Verify: Comments explain technical terms
- [ ] **TC-Q4:** Code follows language best practices
  - Python: PEP 8 style guidelines
  - JavaScript: Standard JS conventions
  - Verify: Proper indentation, naming conventions

**3. Integration Tests (System Integration)**

- [ ] **TC-I1:** FriendliAI API integration
  - Test: Call `generate_code_snippet()` function
  - Expected: Successful API call and response
  - Verify: Proper error handling for API failures
- [ ] **TC-I2:** Response model integration
  - Expected: Code snippet includes all metadata fields
  - Verify: `code`, `language`, `description` are populated
- [ ] **TC-I3:** First skill only receives code
  - Input: 3 skills returned from skill gap analysis
  - Expected: Only first skill has `code_snippet` populated
  - Verify: Skills 2 and 3 have `code_snippet = None`
- [ ] **TC-I4:** End-to-end workflow
  - Test: Complete flow from user input to code generation
  - Verify: Code generation integrates seamlessly with previous steps

**4. Error Handling Tests (Resilience)**

- [ ] **TC-E1:** Handle FriendliAI API timeout
  - Simulate: API timeout (>10 seconds)
  - Expected: Graceful error handling with fallback
  - Verify: System continues, returns generic code example
- [ ] **TC-E2:** Handle invalid API response
  - Simulate: Malformed response from FriendliAI
  - Expected: Error logged, fallback code provided
  - Verify: User still receives a code snippet
- [ ] **TC-E3:** Handle authentication failure
  - Simulate: Invalid or missing API key
  - Expected: Clear error message logged
  - Verify: Appropriate fallback behavior
- [ ] **TC-E4:** Handle code generation failure
  - Simulate: LLM returns non-code content
  - Expected: Validation catches issue, uses fallback
  - Verify: System doesn't crash

**5. Security Tests (Code Safety)**

- [ ] **TC-S1:** No system calls in generated code
  - Verify: Code doesn't contain `os.system()`, `subprocess`, etc.
  - Test: Run security validation function
- [ ] **TC-S2:** No file operations in generated code
  - Verify: Code doesn't contain file I/O operations
  - Test: Check for `open()`, `write()`, `read()` patterns
- [ ] **TC-S3:** No network operations in generated code
  - Verify: Code doesn't contain `requests`, `urllib`, `fetch`
  - Test: Security validation passes
- [ ] **TC-S4:** No dangerous imports
  - Verify: Code doesn't import `eval`, `exec`, `__import__`
  - Test: Import validation passes

**6. User Experience Tests (Usability)**

- [ ] **TC-U1:** Code is readable
  - Verify: Proper formatting and indentation
  - Verify: Clear variable names
  - Test: Non-technical reviewer can understand purpose
- [ ] **TC-U2:** Code is copy-paste friendly
  - Test: Copy code from UI and paste into IDE
  - Expected: No formatting issues, runs immediately
- [ ] **TC-U3:** Description is helpful
  - Verify: Description explains what the code does
  - Verify: Description mentions key concepts demonstrated
- [ ] **TC-U4:** Language detection is accurate
  - Test: Various skills map to correct languages
  - Verify: Python skills → Python, React → JavaScript, etc.

#### Test Data Sets

**Common Skills to Test:**

- Python: "Machine Learning", "Data Science", "Python", "TensorFlow"
- JavaScript: "React", "Node.js", "Vue", "Angular"
- Other: "Docker", "SQL", "Java", "Problem Solving"

**Edge Cases:**

- Empty skill name
- Very long skill name
- Skill with special characters
- Ambiguous skill (could be multiple languages)

#### Acceptance Testing Checklist

Before marking story as "Done", verify:

- [ ] All functional tests pass (TC-F1 through TC-F5)
- [ ] At least 80% of quality tests pass (TC-Q1 through TC-Q4)
- [ ] All integration tests pass (TC-I1 through TC-I4)
- [ ] All error handling tests pass (TC-E1 through TC-E4)
- [ ] All security tests pass (TC-S1 through TC-S4)
- [ ] At least 75% of UX tests pass (TC-U1 through TC-U4)
- [ ] Manual review confirms code quality and educational value
- [ ] Product Owner approves generated code examples

### Error Handling

- Implement try-catch blocks for FriendliAI code generation calls
- Return meaningful error messages to the orchestrator
- Log all errors for debugging purposes
- Provide fallback behavior if code generation fails (e.g., return a generic "Hello World" example)
- Ensure the system can continue even if code generation fails (code snippet is optional)

### Performance Considerations

- Set appropriate timeout values for code generation (e.g., 10 seconds)
- Code generation should not significantly delay the overall response time
- Consider caching generated code for common skills (optional for MVP)

### Security Considerations

#### Code Validation Rules

Implement a `validate_code_safety()` function with these checks:

**1. Prohibited Patterns (Regex-based detection)**

```python
PROHIBITED_PATTERNS = [
    r'os\.system',
    r'subprocess\.',
    r'eval\(',
    r'exec\(',
    r'__import__',
    r'open\(',
    r'file\(',
    r'requests\.',
    r'urllib\.',
    r'socket\.',
    r'pickle\.',
]
```

**2. Prohibited Imports**

```python
PROHIBITED_IMPORTS = [
    'os', 'sys', 'subprocess', 'socket',
    'pickle', 'shelve', 'marshal',
    'requests', 'urllib', 'http',
]
```

**3. Validation Logic**

- Scan generated code for prohibited patterns
- Check import statements against prohibited list
- If violations found, log warning and use safe fallback
- All validation failures should be logged for review

**4. Safe Fallback Examples**

Maintain a library of pre-approved, safe code examples:

```python
SAFE_FALLBACKS = {
    "python": """# Simple Python example
numbers = [1, 2, 3, 4, 5]
squared = [n**2 for n in numbers]
print(f"Squared numbers: {squared}")
""",
    "javascript": """// Simple JavaScript example
const numbers = [1, 2, 3, 4, 5];
const squared = numbers.map(n => n ** 2);
console.log('Squared numbers:', squared);
"""
}
```

**5. Display Safety**

- Escape HTML special characters before rendering
- Use proper code block formatting in frontend
- Prevent XSS through code injection

**6. Execution Safety**

- Primary safety: Daytona sandbox (Story 1.6)
- Secondary safety: Code validation (this story)
- Tertiary safety: User awareness (display warnings)

**7. Monitoring & Logging**

- Log all security validation failures
- Track which skills trigger security issues
- Review logs regularly to improve validation rules

**Note:** These are defense-in-depth measures. The primary security mechanism is Daytona's sandboxed execution in Story 1.6.

## Definition of Done

### Implementation Checklist

- [ ] `generate_code_snippet(skill: str)` function implemented in [`api/friendli_client.py`](api/friendli_client.py:1)
- [ ] Skill-to-language mapping logic implemented
- [ ] Prompt template for code generation created
- [ ] Code validation function implemented
- [ ] Security checks implemented (prohibited patterns, imports)
- [ ] Safe fallback examples library created
- [ ] Response model updated with `CodeSnippet` class
- [ ] Integration with main orchestrator in [`api/index.py`](api/index.py:1)

### Testing Checklist

- [ ] All functional tests pass (5/5)
- [ ] Quality tests pass (minimum 3/4)
- [ ] All integration tests pass (4/4)
- [ ] All error handling tests pass (4/4)
- [ ] All security tests pass (4/4)
- [ ] UX tests pass (minimum 3/4)
- [ ] Test script created for manual testing
- [ ] Edge cases tested and documented

### Quality Checklist

- [ ] Generated code is functional and runnable for common skills
- [ ] Code includes explanatory comments (minimum 2-3 per snippet)
- [ ] Code demonstrates core concepts, not just "Hello World"
- [ ] Code is beginner-friendly and educational
- [ ] Code follows language-specific best practices
- [ ] Code length is appropriate (5-10 lines)

### Integration Checklist

- [ ] Language detection works correctly for different skill types
- [ ] Code snippet integrated into API response with metadata
- [ ] Only first skill receives code snippet
- [ ] Metadata includes: code, language, description
- [ ] Error handling provides graceful fallbacks
- [ ] Logging implemented for debugging

### Security Checklist

- [ ] Code validation function prevents dangerous patterns
- [ ] Security checks tested with malicious inputs
- [ ] Safe fallback examples verified
- [ ] All security tests pass
- [ ] Security validation failures logged

### Documentation Checklist

- [ ] Function docstrings complete
- [ ] Code generation examples documented
- [ ] Security validation rules documented
- [ ] Testing procedures documented
- [ ] Known limitations documented

### Acceptance Checklist

- [ ] Product Owner review and approval
- [ ] Manual testing confirms code quality and user value
- [ ] Demo prepared showing code generation for 3+ skills
- [ ] Ready for integration with Story 1.6 (Daytona validation)

## Change Log

| Date       | Version | Description                                            | Author               |
| :--------- | :------ | :----------------------------------------------------- | :------------------- |
| 2025-10-02 | 1.0     | Initial draft                                          | Scrum Master         |
| 2025-10-02 | 1.1     | PO review: Enhanced user focus and acceptance criteria | Product Owner        |
| 2025-10-02 | 1.2     | QA review: Enhanced testing strategy and security      | Test Architect & QA  |
| 2025-10-02 | 2.0     | Implementation completed - All tests passing           | Full Stack Developer |
